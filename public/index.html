<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Yuvi Panda" />
<meta property="og:description" content="[JupyterHub](https://github.com/jupyterhub/jupyterhub) | [MyBinder](https://mybinder.org) | [Kubernetes](https://k8s.io) | Open Culture" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://words.yuvi.in/" />
<meta property="og:updated_time" content="2018-12-23T19:44:53-08:00"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Yuvi Panda"/>
<meta name="twitter:description" content="[JupyterHub](https://github.com/jupyterhub/jupyterhub) | [MyBinder](https://mybinder.org) | [Kubernetes](https://k8s.io) | Open Culture"/>
<meta name="generator" content="Hugo 0.47.1" />


    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Blog",
  "headline": "Yuvi Panda",
  "url" : "http://words.yuvi.in/",
  "author": {
    "@type": "Person",
    "name": ""
  },
  "dateModified": "2018-12-23T19:44:53-08:00",
  "keywords": "books,class-notes,code,devlog,education,events,jupyter,kubernetes,links,lol-culture,papers,personal,project-ideas,retrospective,so-called-it,uncategorized,wiki,work-plan,algorithm,android,anniversary,answers,athiesm,atleast-not-yet,bigco,bigotry,binder,blogging,book,code,crime,democratizing-programming,devlog,devlog-dec-2011,education,external-enforcement,fiction,flipkart,india,interview,it,js,learning,link,linux,note-to-future-self,opensource,parenting,personal,photo,photography,php,python,rant,reddit,reprint,resistance,review,rights,sick,sriram,systemd,talk,talks,travel,twitter,wordpress,work,yahoo,",
  "description": "[JupyterHub](https://github.com/jupyterhub/jupyterhub) | [MyBinder](https://mybinder.org) | [Kubernetes](https://k8s.io) | Open Culture"
}
</script>


    <link rel="canonical" href="http://words.yuvi.in/">

    <title>Yuvi Panda</title>

    <!-- combined, minified CSS -->
    <link href="http://words.yuvi.in/css/style.css" rel="stylesheet" integrity="sha384-O8wjsnz02XiyrPxnhfF6AVOv6YLBaEGRCnVF&#43;DL3gCPBy9cieyHcpixIrVyD2JS5" crossorigin="anonymous">

    
    <!-- RSS 2.0 feed -->
    <link href="http://words.yuvi.in/index.xml" rel="alternate" type="application/rss+xml" title="Yuvi Panda" />
    

    

    

    

  </head>

  <body>

    <div class="blog-masthead">
    
    </div>

    <header class="blog-header">
      <div class="container">
        <h1 class="blog-title">
            
            <img src='/profile.jpg' width=80 style="border-radius: 50%; margin-bottom: 12px;">
            <a href="http://words.yuvi.in/" rel="home">Yuvi Panda</a></h1>
        <p class="lead blog-description"><a href="https://github.com/jupyterhub/jupyterhub">JupyterHub</a> | <a href="https://mybinder.org">MyBinder</a> | <a href="https://k8s.io">Kubernetes</a> | Open Culture</p>
      </div>
    </header>

    <div class="container">
      <div class="row">
        <div class="col-sm-8 blog-main">

          







<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/devlog-2018-12-23/">DevLog 2018 December 23</a></h2>
    <p class="blog-post-meta"><time datetime="2018-12-23T19:44:53-08:00">Sun Dec 23, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/code" rel="category tag">code</a>, <a href="/categories/devlog" rel="category tag">devlog</a>


</p>
  </header>
  

<p>I have enjoyed keeping running logs of my coding work (devlogs)
in the past, and am going to start doing those again now.</p>

<p>This &lsquo;holiday&rsquo; season, I am spending time teaching myself
skills I sortof know about but do not have a deep understanding of.</p>

<h2 id="jupyterlab-extension">JupyterLab extension</h2>

<p>I spent the first part of the day (before I started devlogging)
working on finishing up a <a href="https://github.com/yuvipanda/jupyterlab-nbmetadata">jupyterlab extension</a>
I started the day before. It lets you <a href="https://github.com/jupyterlab/jupyterlab/issues/1308">edit notebook metadata</a>.
I got started since I wanted to use <a href="https://github.com/mwouts/jupytext">Jupytext</a>
for my work on publishing <a href="https://github.com/yuvipanda/mybinder.org-analytics">mybinder.org-analytics</a>.</p>

<p>TypeScript was easy to pick up coming from C#. I wish the
phospor / JupyterLab code had more documentation though.</p>

<p>I ran into <a href="https://github.com/jupyterlab/jupyterlab/issues/5802">a bug</a>.
While following instructions to set up a JupyterLab dev
setup, I somehow managed to <a href="https://github.com/jupyterlab/jupyterlab/issues/5803">delete my source code</a>.
Thankfully I got most of it back thanks to a saved copy
in vscode. It was a sour start to the morning though.</p>

<p>I&rsquo;ll get back on to this once the sour taste is gone,
and hopefully the bug is fixed :)</p>

<h2 id="asyncio-what-s-next-yuri-selivanov-pybay-2018">asyncio: what&rsquo;s next | Yuri Selivanov @ PyBay 2018</h2>

<p>I&rsquo;ve been trying to get a better handle on asyncio. I can
use it, but I don&rsquo;t fully understand it - I am probably leaving
bugs everywhere&hellip;</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/vem5GHboRNM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>From one of the asyncio maintainers. Gave me some impetus
to <a href="https://github.com/jupyter/repo2docker/pull/539">push the default version of Python</a> on mybinder.org to 3.7 :D
I&rsquo;m most excited about getting features from Trio &amp; Curio into
the standard library. Was good to hear that nobody can quite
figure out exception handling, and not just me.</p>

<p>I discovered <a href="https://github.com/observerss/aioutils">aioutils</a>
while searching around after this. I&rsquo;ve copy pasted code that
theoretically does the same things as <code>Group</code> and <code>Pool</code> from
<code>aioutils</code>, but I&rsquo;ve no idea if they are right. I&rsquo;ll be using
this library from now!</p>

<h2 id="processing-signals">Processing Signals</h2>

<p>I&rsquo;m writing a simple process supervisor library to replace the
janky parts of nbserverproxy. It should have the following
features:</p>

<ol>
<li>Restart processes when they die</li>
<li>Propagate signals appropriately</li>
<li>Support a sense of &lsquo;readiness&rsquo; probes (not liveness)</li>
<li>Be very well tested</li>
<li>Run on asyncio</li>
</ol>

<p>This is more difficult than it seems, and am slowly working my
way through it. (1) isn&rsquo;t too difficult.</p>

<p>(2) is a fair bit more difficult. <code>atexit</code> is useless since it doesn&rsquo;t do
anything with SIGTERM. So I need to manage my own SIGTERM
handlers. However, this means there needs to be a centralish
location of some sort that decides <em>when</em> to exit. This introduces
global state, and I don&rsquo;t like that at all. But unix signals are
global, and maybe there&rsquo;s nothing for me to do here.</p>

<p>I initially created a Supervisor class that holds a bunch of
SupervisedProcess&rsquo;s, but it was still calling sys.exit in it.
Since signals are global, I realize there&rsquo;s no other real
way to handle this, and so I made a global handler setup too.
This has the additional advantage of being able to remove
handlers when a SupervisedProcess dies, avoiding memory
leaks and stuff.</p>

<p>Testing this stuff is hard!</p>

<p>I also need to make sure I don&rsquo;t end up with lots of races.
I&rsquo;m still writing concurrent code, even without threads.
Gotta be careefull. Especially with signals thrown in. Although
I guess once you get a SIGTERM or SIGINT inconsistent state
is not particularly worrysome.</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/oss-in-the-cloud/">Freedoms for Open Source Software users in the Cloud</a></h2>
    <p class="blog-post-meta"><time datetime="2018-08-15T22:41:17-06:00">Wed Aug 15, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/code" rel="category tag">code</a>


</p>
  </header>
  <p><em>This post is from conversations with <a href="http://matthewrocklin.com/">Matt
Rocklin</a> and others at the
<a href="http://pangeo.io/">PANGEO</a> developer meeting at
<a href="https://ncar.ucar.edu/">NCAR</a></em></p>

<p>Today, almost all of &lsquo;the cloud&rsquo; is run by
ruthlessly competitive hypercapitalist large scale
organizations. This is great &amp; terrible.</p>

<p>When writing open source applications that primarily
run on the cloud, I try to make sure my users (primarily
people deploying my software for <em>their</em> users) have
the following freedoms:</p>

<ol>
<li><strong>They can run the software on any cloud provider they
choose to</strong></li>
<li><strong>They can run the software on a bunch of computers they
physically own, with the help of other open source software
only</strong></li>
</ol>

<p>Ensuring these freedoms for my users requires the following
restrictions on me:</p>

<ol>
<li>Depend on Open Source Software with hosted cloud versions,
not proprietary cloud-vendor-only software.</li>
</ol>

<p>I&rsquo;ll use PostgreSQL over Google Cloud Datastore. Kubernetes with
   autoscaling over talking to the EC2 api directly.</p>

<ol>
<li>Use abstractions that allow swappable implementations anytime
you have to talk to a cloud provider API directly.</li>
</ol>

<p>Don&rsquo;t talk to the S3 API directly, but have an abstract
   interface that defines exactly what your application needs,
   and then write an S3 implementation for it. Ideally, also
   write a minio / ceph / file-system implementation for it,
   to make sure your abstraction actually works.</p>

<p>These are easy to follow once you are aware of them, and provide
good design tradeoffs for Open Source projects. Remember these are
necessary but not sufficient to ensure some of your users&rsquo; fundamental
freedoms.</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/aug-2018-plan/">Aug 2018 Work Plan</a></h2>
    <p class="blog-post-meta"><time datetime="2018-07-21T18:32:53-07:00">Sat Jul 21, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/work-plan" rel="category tag">work-plan</a>, <a href="/categories/code" rel="category tag">code</a>


</p>
  </header>
  

<p>I&rsquo;m writing up monthly &lsquo;work plans&rsquo; to plan what work I&rsquo;m trying to do every
month, and do a retrospective after to see how much I got done. I work across
a variety of open source projects with ambiguous responsibilities, so work
planning isn&rsquo;t very set. This has proven to be somewhat quite stressful for
everyone involved. Let&rsquo;s see if this helps!</p>

<h2 id="jupytercon">JupyterCon</h2>

<p>JupyterCon is in NYC towards the end of August, and it is going to set the pace
for a bunch of stuff. I have 2.5-ish talks to give. Need to prepare for those and
do a good job.</p>

<h2 id="matomo-formerly-piwiki-on-mybinder-org">Matomo (formerly Piwiki) on mybinder.org</h2>

<p>mybinder.org currently uses Google Analytics. I am not a big fan. It has troubling
privacy implications, and we don&rsquo;t get data as granularly as we want to. I am going
to try deploying <a href="https://matomo.org/">Matomo</a> (formerly Piwiki) and using that
instead. Run both together for a while and see how we like it! Matomo requires
a MySQL database &amp; is written in PHP - let&rsquo;s see how this goes ;)</p>

<h2 id="the-littlest-jupyterhub-0-1-release">The Littlest JupyterHub 0.1 release</h2>

<p><a href="https://github.com/jupyterhub/the-littlest-jupyterhub">The Littlest JupyterHub</a> is
doing great! I&rsquo;ve done a <strong>lot</strong> of user tests, and the distribution has changed
drastically over time. It&rsquo;s also the first time I&rsquo;m putting my newly found
strong convictions around testing, CI &amp; documentation to practice. You can already
check it out <a href="https://github.com/jupyterhub/the-littlest-jupyterhub">on GitHub</a>. I
want to make sure we (the JupyterHub team) gets out a 0.1 release early August.</p>

<h2 id="pangeo-workshop">Pangeo Workshop</h2>

<p>I despair about climate change and how little agency I seem to have around it
quite a bit. I&rsquo;m excited to go to the <a href="https://www2.cisl.ucar.edu/events/workshops/2018-pangeo-workshop/2018/2018-pangeo-workshop">PANGEO workshop</a>
in Colorado. I&rsquo;m mostly hoping to listen &amp; understand their world some more.</p>

<h2 id="berkeley-datahub-deployment">Berkeley DataHub deployment</h2>

<p>Aug 20-ish is when next semester starts at UC Berkeley. I need to have a pretty
solid JupyterHub running there by then. I&rsquo;d like it to have good CI/CD set up
in a generic way, rather than something super specific to Berkeley. However,
I&rsquo;m happy to shortcut this if needed, since there&rsquo;s already so many things on
my plate haha.</p>

<h2 id="uc-davis">UC Davis</h2>

<p>I&rsquo;m trying to spend a day or two a month at UC Davis. Partially because I like
being on Amtrak! I also think there&rsquo;s a lot of cool work happening there,
and I&rsquo;d like to hang out with all the cool people doing all the cool work.</p>

<h2 id="personal">Personal</h2>

<p>On top of this, there&rsquo;s ongoing medical conditions to be managed. I&rsquo;m getting
Carpel Tunnel Release surgery sometime in October, so need to make sure I do
not super fuck up my hands before then. I&rsquo;m also getting a cortisone shot
for my back in early August to deal with Sciatica. Fun!</p>

<h2 id="things-i-m-not-doing">Things I&rsquo;m not doing!</h2>

<p>The grading related stuff I&rsquo;ve been working on is going to the backburner
for a while. I think I bit off far more than I can chew, so time to back off.
I also do not have a good intuition for the problem domain since I&rsquo;ve never
written grading keys nor have I been a student in a class that got autograded.</p>

<h2 id="in-conclusion">In conclusion&hellip;</h2>

<p>Shit, I&rsquo;ve a lot of things to do lol! I&rsquo;m sure I&rsquo;m forgetting some things
here that I&rsquo;ve promised people. Let&rsquo;s see how this goes!</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/conda-constructor-thoughts/">Conda Constructor Thoughts</a></h2>
    <p class="blog-post-meta"><time datetime="2018-06-28T22:43:56-07:00">Thu Jun 28, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/code" rel="category tag">code</a>


</p>
  </header>
  

<p>Inspired by conversations with <a href="https://github.com/bollwyvl">Nick Bollweg</a> and
<a href="http://matthewrocklin.com/">Matt Rocklin</a>, I experimented with using
<a href="https://github.com/conda/constructor">conda constructor</a> as the installer for
<a href="http://words.yuvi.in/post/the-littlest-jupyterhub/">The Littlest JupyterHub</a>.
Theoretically, it fit the bill perfectly - I wanted a way to ship arbitrary
packages in multiple languages (python &amp; node) in an easy to install self-contained way,
didn&rsquo;t want to make debian packages &amp; wanted to use a tool that people in the Jupyter
ecosystem were familiar with. Constructor seemed to provide just that.</p>

<p>I sortof got it working, but in the end ran into enough structural problems that
I decided it isn&rsquo;t the right tool for this job. This blog post is a note to my
future self on <em>why</em>.</p>

<p>This isn&rsquo;t a &lsquo;takedown&rsquo; of conda or conda constructor - just a particular
use case where it didn&rsquo;t work out and a demonstration of how little I know
about conda. It probably works great if you are doing more scientific computing
and less &lsquo;ship a software system&rsquo;!</p>

<h2 id="does-not-work-with-conda-forge">Does not work with <code>conda-forge</code></h2>

<p>I &lt;3 <a href="https://conda-forge.org/">conda-forge</a> and the community around
it. I know there&rsquo;s a nice <a href="https://anaconda.org/conda-forge/jupyterhub">jupyterhub</a>
package there, which takes care of installing JupyterHub, node, and required
node modules.</p>

<p>However, this doesn&rsquo;t actually work. conda constructor does not support
<a href="https://www.anaconda.com/blog/developer-blog/condas-new-noarch-packages/">noarch packages</a>,
and JupyterHub relies on several <code>noarch</code> packages. From my understanding,
more <code>conda-forge</code> packages are moving towards being <code>noarch</code> (for good reason!).</p>

<p>Looking at <a href="https://github.com/conda/constructor/issues/86">this issue</a>,
it doesn&rsquo;t look like this is a high priority item for them to fix anytime soon.
I understand that - they don&rsquo;t owe the world free work! It just makes conda
constructor a no-go for my use case&hellip;</p>

<h2 id="no-support-for-pip">No support for pip</h2>

<p>You can pip install packages in a conda environment, and they mostly just work.
There are a <em>lot</em> of python packages on PyPI that are installable via pip that
I&rsquo;d like to use. constructor doesn&rsquo;t support bundling these, which is entirely
fair! <a href="https://github.com/conda/constructor/pull/96">This PR</a> attempted something
here, but was rejected.</p>

<p>So if I want to keep using packages that don&rsquo;t exist in <code>conda-forge</code> yet but
do exist in pip, I would have to make sure these packages and all their dependencies
exist as conda packages too. This would be fine if constructor was giving
me enough value to justify it, but right now it is not. I&rsquo;ve also tried going
down a similar road (<em>cough</em> debian <em>cough</em>) and did not want to do that again :)</p>

<h2 id="awkward-post-install-bash">Awkward <code>post-install.bash</code></h2>

<p>I wanted to set up systemd units post install. Right off the bat this should
have made me realize conda constructor was not the right tool for the job :D
The only injected environment variable is <code>$PREFIX</code>, which is not super helpful
if you wanna do stuff like &lsquo;copy this systemd unit file somewhere&rsquo;. I ended up
writing a small python module that does all these things, and calling it from
post-install. However, even then I couldn&rsquo;t pass any environment variables to it,
making testing / CI hard.</p>

<h2 id="current-solution">Current solution</h2>

<p>Currently, we have a <a href="https://github.com/yuvipanda/the-littlest-jupyterhub/blob/9cc05a9d627515a01b68e244a970079481be7d9e/installer/install.bash">bootstrap script</a>
that downloads miniconda, &amp; bootstraps from there to a full JupyterHub install.
Things like systemd units &amp; sudo rules are managed by a <a href="https://github.com/yuvipanda/the-littlest-jupyterhub/tree/9cc05a9d627515a01b68e244a970079481be7d9e/tljh">python module</a>
that is called from the bootstrap script.</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/the-littlest-jupyterhub/">The Littlest Jupyterhub</a></h2>
    <p class="blog-post-meta"><time datetime="2018-06-18T13:14:59-07:00">Mon Jun 18, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/jupyter" rel="category tag">jupyter</a>, <a href="/categories/project-ideas" rel="category tag">project-ideas</a>


</p>
  </header>
  

<p>This idea comes from brainstorming along with <a href="https://lindseyjh.ca/">Lindsey
Heagy</a>, <a href="https://www.willingconsulting.com/">Carol
Willing</a>, <a href="https://github.com/betatim">Tim
Head</a> &amp; <a href="https://github.com/bollwyvl">Nick
Bollweg</a> at the Jupyter Team Meeting 2018. Most
of the good ideas are theirs! The name is inspired by <a href="https://en.wikipedia.org/wiki/The_Littlest_Hobo">one of favorite TV
series</a> of one of my
favorite people.</p>

<p>I really love the idea of <a href="https://github.com/jupyterhub/jupyterhub">JupyterHub</a> distributions - opinionated combination
of components that target a specific use case. The <a href="https://z2jh.jupyter.org">Zero to JupyterHub</a>
distribution is awesome &amp; works for most people. However, it requires
<a href="https://kubernetes.io">Kubernetes</a> - a distributed system with inherent complexities that is not
worth it below a certain threshold.</p>

<p>This blog post lays out ideas for implementing a simpler, smaller distribution called
<em>The Littlest JupyterHub</em>. The Littlest JupyterHub serves <a href="https://en.wikipedia.org/wiki/Long_tail">the long tail</a> of potential JupyterHub users
who have the following needs only.</p>

<ol>
<li>Support a very small number of students (around 20–30, maybe 50)</li>
<li>Run on only one node, either <a href="http://digitalocean.com/">a cheap VPS</a> or a
VM on their <a href="https://cloud.google.com">favorite cloud provider</a></li>
<li>Provide the same environment for all students</li>
<li>Allow the instructor / admin to easily modify the environment for students with no specialized knowledge</li>
<li>Be extremely low maintenance once set up &amp; easily fixable when it breaks</li>
<li>Allow easy upgrades</li>
<li>Enforce memory / CPU limits for students</li>
</ol>

<p>The target audience is primarily educators teaching small classes with
Jupyter Notebooks. It should be an extremely focused distribution, with new
feature requests facing higher scrutiny than usual. It has a legitimate
chance of actually reaching 1.0 &amp; being stable, requiring minimal ongoing
upgrades!</p>

<h2 id="jupyterhub-setup">JupyterHub setup</h2>

<p>JupyterHub +
<a href="https://github.com/jupyterhub/configurable-http-proxy">ConfigurableHTTPProxy</a>
run as standard <a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html">systemd services</a>.
<a href="https://github.com/jupyterhub/systemdspawner">Systemd spawner is used</a> - it is lightweight, allows JupyterHub
restarts without killing user servers &amp; provides CPU / memory isolation.</p>

<p>Something like <a href="https://github.com/yuvipanda/jupyterhub-firstuseauthenticator">First Use
Authenticator</a>
+ a user whitelist might be good enough for a large number of users. New
authenticators are added whenever users ask for them.</p>

<p>The JupyterHub system is in its own root owned conda environment or
virtualenv, to prevent accidental damage from users.</p>

<h2 id="user-environment">User environment</h2>

<p>There is a single
conda environment shared by all the users. JupyterHub admins have
write access to this environment, and everyone else has read access. Admins
can install new libraries for all users with conda/pip. No extra steps
needed, and you can do this from inside JupyterHub without needing to ssh.</p>

<p>Each user gets their own home directory, and can install packages there if
they wish. systemdspawner puts each user server in a systemd service, and
provides <a href="https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html">fine grained
control</a>
over memory &amp; cpu usage. Users also get their own system user, providing an
additional layer of security &amp; standardized home directory locations.</p>

<h2 id="configuration">Configuration</h2>

<p><a href="http://yaml.org/">YAML</a> is used for config - it is the
least bad of all the currently available languages, IMO. Ideally, something
like the <a href="https://www.sudo.ws/man/1.8.17/visudo.man.html"><code>visudo</code></a> command
would exist for editing &amp; applying this config. It&rsquo;ll
open the config file in an editor, allow users to edit it, and apply it only
if it is valid. Advanced users can sidestep this and edit files directly. The
YAML file is read and processed directly in <code>jupyterhub_config.py</code>. This
simplifies things &amp; gives us fewer things to break.</p>

<h2 id="upgrading-the-distribution">Upgrading the distribution</h2>

<p>Backwards compatible upgrading will be supported across one
minor version only - so you can go from 0.7 to 0.8, but not 0.9. Upgrades
should not cause outages.</p>

<h2 id="installation-mechanism">Installation mechanism</h2>

<p>Users run a command on a fresh server to install this distribution. This could use
conda constructor (thanks to Nick Bollweig &amp; <a href="http://matthewrocklin.com/">Matt
Rocklin</a> for convincing me!)
or debian packages (with fpm or dh-virtualenv). The user environments will be
<a href="https://conda.io/">conda environments</a>.</p>

<p>A <code>curl &lt;some-url&gt; | sudo bash</code> command is available in a
nice looking website for the distribution that users can copy paste into
their fresh VM. This website also has instructions for creating a fresh VM in
popular cloud providers &amp; VPS providers.</p>

<h2 id="debuggability">Debuggability</h2>

<p>All systems exist in a partially degraded state all the time. Good systems
self-heal &amp; continue to run as well as they can. When they can&rsquo;t, they break
cleanly in known ways. They are observable enough to debug the issues that
cause 80% of the problems.</p>

<p>The Littlest JupyterHub should be a good system. Systemd captures
logs from JupyterHub, user servers &amp; the proxy. Strong validation of the
config file catches fatal misconfigurations. Reboots actually fix most issues
and never make anything worse. Screwed up user environments are recoverable.</p>

<p>We&rsquo;ll discover how this breaks as users of varying skill levels use it, and
update our tooling accordingly.</p>

<h2 id="but-no-docker">But, No Docker?</h2>

<p>Docker has been explicitly excluded from this tech stack. Building custom
docker images &amp; dealing with registries is too complex most educators. A good
distribution embraces its constraints &amp; does well!</p>

<h2 id="contribute">Contribute</h2>

<p>Are you a person who would use a distribution like this? We would love to
hear from you! Make an issue <a href="https://github.com/yuvipanda/the-littlest-jupyterhub">on GitHub</a>,
<a href="https://twitter.com/yuvipanda">tweet at me</a>, or send me <a href="mailto:yuvipanda@gmail.com">an email</a>.</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/kubectl-rbac/">Kubectl verbose logging tricks</a></h2>
    <p class="blog-post-meta"><time datetime="2018-01-11T15:15:58-08:00">Thu Jan 11, 2018</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/kubernetes" rel="category tag">kubernetes</a>, <a href="/categories/code" rel="category tag">code</a>


</p>
  </header>
  <p>Recently I had to write some code that had to call the kubernetes API directly,
without any language wrappers. While there is pretty good <a href="https://kubernetes.io/docs/reference/">reference docs</a>,
I didn&rsquo;t want to go and construct all the JSON manually in my programming language.</p>

<p>I discovered that <code>kubectl</code>&rsquo;s <code>-v</code> parameter is very useful for this! With this,
I can do the following:</p>

<ol>
<li>Perform the actions I need to perform with just <code>kubectl</code> commands</li>
<li>Pass <code>-v=8</code> to kubectl when doing this, and this will print all the HTTP traffic
(requests and responses!) in an easy to read way</li>
<li>Copy paste the JSON requests and template them as needed!</li>
</ol>

<p>This was very useful! The fact you can see the response bodies is also nice,
since it gives you a good intuition of how to handle this in your own code.</p>

<p>If you&rsquo;re shelling out to <code>kubectl</code> directly in your code (for some reason!),
you can also use this to figure out all the RBAC rules your code would need. For
example, if I&rsquo;m going to run the following in my script:</p>

<pre><code class="language-bash">kubectl get node
</code></pre>

<p>and need to figure out which RBAC rules are needed for this, I can run:</p>

<pre><code class="language-bash">kubectl -v=8 get node 2&gt;&amp;1 | grep -P 'GET|POST|DELETE|PATCH|PUT'
</code></pre>

<p>This should list all the API requests the code is making, making it easier
to figure out what rules are needed.</p>

<p>Note that you might have to <code>rm -rf ~/.kube/cache</code> to &lsquo;really&rsquo; get the
full API requests list, since <code>kubectl</code> caches a bunch of API autodiscovery.
The minimum RBAC for kubectl is:</p>

<pre><code class="language-yaml">kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: kubectl-minimum
rules:
- nonResourceURLs: [&quot;/api&quot;, &quot;/apis/*&quot;]
  verbs: [&quot;get&quot;]
</code></pre>

<p>You will need to add additional rules for the specific commands you
want to execute.</p>

<p><strong>More Kubectl Tips</strong></p>

<ol>
<li><a href="https://schd.ws/hosted_files/kccncna17/de/Stupid%20Kubectl%20Tricks.pdf">Slides from the &lsquo;Stupid Kubectl Tricks&rsquo; KubeCon talk</a></li>
<li><a href="https://coreos.com/blog/kubectl-tips-and-tricks">On the CoreOS blog</a></li>
<li><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">Terse but useful official documentation</a></li>
</ol>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/2017/">2017</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-29T16:29:00-08:00">Fri Dec 29, 2017</time> by  in 
<i class="fa fa-folder" aria-hidden="true"></i>&nbsp;<a href="/categories/personal" rel="category tag">personal</a>, <a href="/categories/retrospective" rel="category tag">retrospective</a>


</p>
  </header>
  

<p>I haven&rsquo;t done a &lsquo;year in retrospective&rsquo; publicly for a long time, but after reading
Alice Goldfuss&rsquo; <a href="http://blog.alicegoldfuss.com/2017-year-in-review/">2017 year in review</a> decided
to do one for me too!</p>

<p>This is a very filtered view - there are lots of important people &amp; events in 2017
that are not contained here, and that is ok.</p>

<h2 id="professional">Professional</h2>

<ul>
<li><p><strong>New Job</strong></p>

<p>I finished around 6-ish years at the Wikimedia Foundation, and joined UC Berkeley&rsquo;s
<a href="http://data.berkeley.edu/">Data Science Division</a> early in the year. I grew
immensely as a person &amp; programmer in that time. The new job gives me a lot more
responsibility and it is quite fun.</p>

<p>At Berkeley, I build infrastructure for students to dive into writing code to solve
their own problems in their own fields without having to navigate the accidental
complexities of software installation &amp; configuration as much as possible. This
is in line with my previous work like <a href="https://quarry.wmflabs.org">Quarry</a> or
<a href="https://paws.wmflabs.org">PAWS</a>, except it&rsquo;s my main paid-for job now rather than a
side project, which is great! It lets me work
full time in realizing some of the ideas from my talk on
<a href="https://bids.berkeley.edu/resources/videos/stealing-some-wikimedias-principles-democratize-programming">democratizing programming</a>.
I&rsquo;m happy with the kind of work I&rsquo;m doing,
the people I am doing it with, the scale I am doing it at and the impact I think
it is having. I feel lucky &amp; privileged to be able to do it!</p>

<p>Wherever I go, whatever I do - good or bad - Wikimedia
will always be partially responsible for that :)</p></li>

<li><p><strong>Working closer to users</strong></p>

<p>At my Wikimedia Job, I was partially responsible for maintaining the
<a href="https://tools.wmflabs.org">Tool Labs</a> infrastructure. Others (mostly volunteers) built the tools
that end users actually used. While this was still good, it made me one step
removed from the actual end users. At Berkeley, end users (both students &amp;
faculty) directly use the infrastructure I build
This increase in directness has given me a lot of joy, happiness &amp;
confidence about the impact of the work I&rsquo;m doing.</p></li>

<li><p><strong>MyBinder</strong></p>

<p>I helped rewrite &amp; redeploy <a href="https://mybinder.org">mybinder.org</a> as part of
the mybinder team, which was one of the high points of the year! It has had
the most public facing impact of all the projects I&rsquo;ve worked on this year - even
got a <a href="https://jvns.ca/blog/2017/11/12/binder--an-awesome-tool-for-hosting-jupyter-notebooks/">glowing review</a>
from Juilia Evans! We&rsquo;re now temporarily funded via a grant from the Moore
Foundation, and need to find long term sustainable solutions. We
have a lot of low hanging fruit to take on in the next year, so I am super
excited for it!</p></li>

<li><p><strong>Academia</strong></p>

<p>I&rsquo;m now sort-of accidentally &lsquo;inside&rsquo; Academia as defined in the US, which
is a strange and surreal experience. I&rsquo;m &lsquo;staff&rsquo;, which seems to
be a distinct and different track than the grad student -&gt; post grad -&gt; faculty
track. From the inside, it is many moving parts than one behemoth - some move
fast, some slow &amp; super cool stuff / tension at the intersections.
I don&rsquo;t fully understand my place in it yet, but maybe someday I will!</p></li>

<li><p><strong>Teams</strong></p>

<p>At Wikimedia, I was in a team of (otherwise amazing!) operations folks that was mostly white and
male. Now, I&rsquo;m in multiple diverse &amp; multi-disciplinary teams, and it is <em>amazing</em>. I find it easier to do more impactful work, grow technically &amp; professionally, build consensus and have fun. Hard to go back!</p></li>

<li><p><strong>Intersections</strong></p>

<p>I spend time at the <a href="https://bids.berkeley.edu/">Berkeley Institute for Data Science</a>,
with the interesting variety of people who are there. They&rsquo;re all very smart
in different fields than I am in, and the intersection is great. I walk away
from every conversation with anyone feeling both dumber &amp; smarter for the new knowledge
of things I now knew I didn&rsquo;t know! Cool (and sometimes uncomfortable) things
happen at intersections, and I want to make sure I keep being in those spaces.</p></li>
</ul>

<h2 id="community">Community</h2>

<ul>
<li><p><strong>I am a Maintainer</strong></p>

<p>With enough involvement in the <a href="http://jupyter.org/">Jupyter</a> community, I have
now found myself to be an actual <strong>Maintainer</strong> of open source projects in ways
I was not when I was at Wikimedia. Took me a while to realize this comes with a lot of
responsibility and work that&rsquo;s not just &lsquo;sit and write code&rsquo;. I am still
coming to terms with it, and it&rsquo;s not entirely fully clear to me what the
responsibilities I now have are. Thankfully I&rsquo;m not a solo maintainer but have
wonderful people who have a lot of experience in this kinda stuff doing it with
me!</p></li>

<li><p><strong>Talks</strong></p>

<p>I was involved in 3 talks (
<a href="https://www.youtube.com/watch?v=hgkYbb6aEP4&amp;list=PL055Epbe6d5aP6Ru42r7hk68GTSaclYgi&amp;index=44">1</a>
<a href="https://www.youtube.com/watch?v=ivswAxysfTk&amp;list=PL055Epbe6d5aP6Ru42r7hk68GTSaclYgi&amp;index=38">2</a>
<a href="https://www.youtube.com/watch?v=VStVq4gLfCY&amp;list=PL055Epbe6d5aP6Ru42r7hk68GTSaclYgi&amp;index=69">3</a>
)
and 1 tutorial at JupyterCon this year, which was a
mistake I shall not make again. I also gave <a href="https://www.youtube.com/watch?v=g5rl7T18n-s">one talk</a> at KubeCon NA 2017.
I am a little out of practice in giving good talks - while these were
okay, I know I can do better. I gave a number of talks to smaller internal audiences
at UC Berkeley &amp; ran a number of JupyterHub related workshops - I quite enjoyed
those and will try to do more of that :)</p></li>

<li><p><strong>Documentation</strong></p>

<p>I finally understood how little I had valued <em>writing</em> good documentation for
my projects and spent time correcting it this year. I still have a long way to
go, but the Jupyter community in general has helped me understand and get better
at it.</p></li>
</ul>

<h2 id="technical">Technical</h2>

<ul>
<li><p><strong>Python skills</strong></p>

<p>I&rsquo;ve started working on python projects again, rather than just scripts. Some of
my skills here have rusted over years of not being heavily used. I got into
writing better tests and found lots of value in them. This is another place where
being part of the Jupyter ecosystem has made it pretty awesome for me.</p></li>

<li><p><strong>Autonomous systems</strong></p>

<p>This year I&rsquo;ve had far more operational responsibilities than I had at Wikimedia,
and it has forced me to both learn more about automation / autonomous systems &amp;
implement several of them. It&rsquo;s been an intense personal growth spurt. I also
have the ability to work with public clouds &amp; a lot of personal freedom on technology
choices (as long as I can support them!), and it&rsquo;s been liberating. It will
be hard for me to go back to working at a place that&rsquo;s automated a lot less.</p></li>

<li><p><strong>Performance analysis + fixing</strong></p>

<p>I did a lot of performance analysis of JupyterHub, in a &lsquo;profile -&gt; fix -&gt; repeat&rsquo;
loop. We got it from failing at around 600ish active users to about 4k-5k now, which
is great. I also learnt a lot about profiling in the process!</p></li>

<li><p><strong>Container internals</strong></p>

<p>I learnt a <em>lot</em> about how containers work at the kernel level. <a href="https://www.lizrice.com/">Liz Rice</a>&rsquo;s
talk <a href="https://www.youtube.com/watch?v=Utf-A4rODH8">Building a container from scratch</a>
made me realize that yes I could also understand containers internally! LWN&rsquo;s
series of articles on <a href="https://lwn.net/Articles/604609/">cgroups</a> and
<a href="https://lwn.net/Articles/531114/">namespaces</a> helped a lot too. I feel better
understanding the hype &amp; figuring out what is actually useful to me :) It pairs
well with the kubernetes knowledge I gained from 2016.</p></li>
</ul>

<h2 id="personal">Personal</h2>

<p>Lots happened here that I can not talk about publicly, but here is some!</p>

<ul>
<li><p><strong>Election &amp; Belonging</strong></p>

<p>The 2016 US Elections were very tough on me, causing a lot of emotional turmoil.
I participated in some protests, became disillusioned with current political systems,
despondent about possible new ones &amp; generally just sad. I feel a bit more resilient,
but know even less than before if the US will be a good long term place for me.
I&rsquo;d like it to be, and am currently operating on the assumption that the Nov 2018
elections in the US will turn better, and I can continue living here. But I am
starting German classes in a week just in case :)</p></li>

<li><p><strong>Visa situation</strong></p>

<p>My visa situation has stabilized somewhat. Due to wonderful efforts of many
people at UC Berkeley, I am possibly going to start my Green Card process soon.
My visa is getting renewed, and I&rsquo;ll have to go back to India in a few months
to get it sorted. It&rsquo;s a lot more stable than it was last year this time!</p></li>

<li><p><strong>Traveling</strong></p>

<p>I did not travel out of the country much this year. I had the best Fried Chicken
of my life in New Orlean&rsquo;s, and good Chicken 65 (!!!) in Austin. I also did my
first ever &lsquo;road trip&rsquo;, from the Bay Area to Seattle! I spent a bit of time in
New York, Portland &amp; Seattle as well - not enough though. Paying bay area rents does
not help with travel :(</p></li>

<li><p><strong>Cooking</strong></p>

<p>I cooked a lot more of the food I ate! I can make it as spicy or sweet as I want,
and it is still healthy if I make it at home (right?). Other people even actually
<em>liked</em> some of the food I made.</p></li>

<li><p><strong>Health</strong></p>

<p>I haven&rsquo;t fully recovered from a knee injury I had in 2016 :( It made me realize
how much I had taken my body for granted. I am taking better care of it now, and
shall continue to. I&rsquo;m doing weights at home, having admitted I won&rsquo;t have the
discipline to actually go to a gym regularly when it is more than a 3 minute walk&hellip;</p></li>

<li><p><strong>Hair</strong></p>

<p>It&rsquo;s been mostly red this year! I might just stick to red from now on. I switched
out my profile picture from random stick figure to a smiling selfie that I actually
like, and it seems to have generally improved my mood.</p></li>
</ul>

<h2 id="in-conclusion">In conclusion</h2>

<ul>
<li>My primary community is now the Jupyter community, rather than the Wikimedia community.
This has had a lot of good cascading changes.</li>
<li>Lots of personal changes, many I can&rsquo;t publicly talk about.</li>
<li>The world is an bleaker &amp; more hopeful place than I had imagined.</li>
</ul>

<p>&lsquo;18!</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/why-not-s2i/">Why repo2docker? Why not s2i?</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-03T01:23:54-08:00">Sun Dec 3, 2017</time> by  in 

<i class="fa fa-tag" aria-hidden="true"></i>&nbsp;<a href="/tags/binder" rel="tag">binder</a>, <a href="/tags/code" rel="tag">code</a>

</p>
  </header>
  

<p><img src="https://imgs.xkcd.com/comics/standards.png" alt="https://xkcd.com/927/" /></p>

<p>The wonderful <a href="https://twitter.com/GrahamDumpleton">Graham Dumpleton</a> asked <a href="https://twitter.com/GrahamDumpleton/status/936740552304836608">on twitter</a> why we built an entirely new tool (<a href="https://github.com/jupyter/repo2docker">repo2docker</a>) instead of using OpenShift&rsquo;s cool <a href="https://github.com/openshift/source-to-image">source2image</a> tool.</p>

<p>This is a very good question, and not a decision we made lightly. This post lays out some history, and explains the reasons we decided to stop using s2i. s2i is still a great tool for most production use cases, and you should use it if you&rsquo;re building anything like a PaaS!</p>

<h2 id="terminology">Terminology</h2>

<p>Before discussing, I want to clarify &amp; define the various projects we are talking about.</p>

<ol>
<li><a href="https://github.com/openshift/source-to-image">s2i</a> is a nice tool from the <a href="http://openshift.org/">OpenShift</a> project that is used to build images out of git repositories. You can use heroku-like buildpacks to specify how the image should be built. It&rsquo;s used in OpenShift, but can also be easily used standalone.</li>
<li><a href="https://github.com/jupyterhub/binderhub">BinderHub</a> is the UI + scheduling component of Binder. This is what you see when you go to <a href="https://mybinder.org">https://mybinder.org</a></li>
<li><a href="https://github.com/jupyter/repo2docker">repo2docker</a> is a standalone python application that takes a git repository &amp; converts it into a docker image containing the environment that is specified in the repository. This heavily overlaps with functionality in s2i.</li>
</ol>

<h2 id="when-repo2docker-just-wrapped-s2i">When repo2docker just wrapped s2i&hellip;</h2>

<p>When we started building <a href="https://github.com/jupyterhub/binderhub">BinderHub</a>, I looked around for a good heroku-like &lsquo;repository to container image&rsquo; builder project. I first looked at Deis&rsquo; <a href="https://github.com/deis/slugbuilder">slugbuilder</a> and <a href="https://github.com/deis/dockerbuilder">dockerbuilder</a> - they didn&rsquo;t quite match our needs, and seemed a bit tied into Deis. I then found OpenShift&rsquo;s <a href="https://github.com/openshift/source-to-image">source2image</a>, and was very happy! It worked pretty well standalone, and <code>#openshift</code> on IRC was very responsive.</p>

<p>So until July 1, we actually used s2i under the hood! <code>repo2docker</code> was a wrapper that performed the following functions:</p>

<ol>
<li>Detect which s2i buildpack to use for a given repository</li>
<li>Support building arbitrary Dockerfiles (s2i couldn&rsquo;t do this)</li>
<li>Support the Legacy Dockerfiles that were required under the old version of mybinder.org. The older version of mybinder.org munged these Dockerfiles, and so we needed to replicate that for compatibility.</li>
</ol>

<p>@minrk did some wonderful work in allowing us to package the s2i binary into our python package, so users didn&rsquo;t even need to download s2i separately. It worked great, and we were happy with it!</p>

<h2 id="moving-off-s2i">Moving off s2i</h2>

<p>Sometime in July, we started adding support for Julia to binder/repo2docker. This brought up an interesting &amp; vital issue - composability.</p>

<p>If a user had a <code>requirements.txt</code> in their repo <em>and</em> a <code>REQUIRE</code> file, then we&rsquo;d have to provide both a Python3 and Julia environment. To support this in s2i, we&rsquo;d have needed to make a <code>python3-julia</code> buildpack.</p>

<p>If it had a <code>requirements.txt</code>, a <code>runtime.txt</code> with contents <code>python-2.7</code> and a <code>REQUIRE</code> file, we&rsquo;d have to provide a Python3 environment, a Python2 environment, and a Julia environment. To support this in s2i, we&rsquo;d have needed to make a <code>python3-python2-julia</code> buildpack.</p>

<p>If it had an <code>environment.yml</code> file and a <code>REQUIRE</code> file, we&rsquo;d have to provide a conda environment and a Julia environment. To do this, we&rsquo;d have to make a <code>conda-julia</code> buildpack.</p>

<p>As we add support for other languages (such as R), we&rsquo;d need to keep expanding the set of buildpacks we had. It&rsquo;d become a combinatorial explosion of buildpacks. This isn&rsquo;t a requirement or a big deal for PaaS offerings - usually a container image should only contain one &lsquo;application&rsquo;, and those are usually built using only one language. If you use multiple languages, you just make them each into their own container &amp; communicate over the network. However, Binder was building images that contained <em>environments</em> that people could explore and do things in, rather than specific applications. Since a lot of scientific computing uses multiple languages (looking at you, the people who do everything in R but scrape using Python), this was a core feature / requirement for Binder. So we couldn&rsquo;t restrict people to single-language buildpacks.</p>

<p>So I decided that we can <em>generate</em> these combinatorial buildpacks in repo2docker. We can have a script that generates the buildpacks at build time, and then we can just check in the generated code. This would let us keep using s2i for doing image builds and pushes, and allow others using s2i to use our buildpacks. Win-win!</p>

<p>This had the following problems:</p>

<ol>
<li>I was generating bash from python. This was quite error prone, since the bash also needed to carefully support the various complex environment specifications we wanted to support.</li>
<li>We needed to <em>sometimes</em> run assemble scripts as root (such as when there is an &lsquo;apt.txt&rsquo; requiring package installs). This would require careful usage of <code>sudo</code> in the generated bash for security reasons.</li>
<li>This was very &lsquo;clever&rsquo; code, and after running into a few bugs here I was convinced this &lsquo;generate bash with python&rsquo; idea was too clever for us to use reliably.</li>
</ol>

<p>At this point I considered making the <code>assemble</code> script into Python, but then I&rsquo;d be either generating Python from Python, or basically writing a full library that will be invoked from inside each buildpack. We&rsquo;d still need to keep repo2docker around (for Dockerfile + Legacy Dockerfile support), and the s2i buildpacks will be quite complex. This would also affect Docker image layer caching, since all activities of <code>assemble</code> are cached as one layer. Since a lot of repositories have similar environments (or are just building successive versions of same repo), this gives up a good amount of caching.</p>

<p>So instead I decided that the right thing to do here is to dynamically generate a Dockerfile in python code, and build / push the image ourselves. S2I was great for generating a best-practices production container that runs one thing and does it well, but for binder we wanted to generate container images that captured complex environments without regard to what can run in them. Forcing s2i to do what we wanted seemed like trying to get a square peg into a round hole.</p>

<p>So in <a href="https://github.com/jupyter/repo2docker/commit/38755650c28fe6c71adec5a5bf9adfdde2d9772e">this heavily squashed commit</a> I removed s2i, and repo2docker became stand alone. It was sad, since I really would have liked to not write extra code &amp; keep leveraging s2i. But the code is cleaner, easier for people to understand and maintain, and the composing works pretty well in understandable ways after we removed it. So IMO it was the right thing to do!</p>

<p>I personally would be happy to go back to using s2i if we can find a clean way to support composability + caching there, but IMO that would make s2i too complex for its primary purpose of building images for a PaaS. I don&rsquo;t see repo2docker and s2i as competitors, as much as tools of similar types in different domains. Lots of &lt;3 to the s2i / openshift folks!</p>

<p>I hope this was a useful read!</p>

<h2 id="tldr">TLDR</h2>

<p>S2I was great for generating a best-practices production container that runs one thing and does it well, but for binder we wanted to generate container images that captured complex environments without regard to what can run in them. Forcing s2i to do what we wanted seemed like trying to get a square peg into a round hole.</p>

<p><em>Thanks to Chris Holgraf, MinRK and Carol Willing for helping read, reason about and edit this blog post</em></p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/maintainerati-2017/">maintainerati 2017</a></h2>
    <p class="blog-post-meta"><time datetime="2017-10-10T23:15:01-07:00">Tue Oct 10, 2017</time> by  in 

<i class="fa fa-tag" aria-hidden="true"></i>&nbsp;<a href="/tags/opensource" rel="tag">opensource</a>

</p>
  </header>
  <p>I was at <a href="http://maintainerati.org/">maintainerati</a> today, which was super fun &amp; quite intense! I highly appreciate GitHub &amp; the individuals involved in making it happen!</p>

<p>Here&rsquo;s my key takeaways from this (and several other conversations over the last few weeks leading up to this):</p>

<ol>
<li>I am now a <em>maintainer</em>, which is quite a different thing from a <em>core contributor</em> or just a <em>contributor</em>. The power dynamics are very different, and so are the responsibilities. I can not ostrich myself into thinking I can just keep writing code and not do anything else - that&rsquo;s a disservice to not just other folks in the project, but also myself.</li>
<li>Being a maintainer is quite hard emotionally &amp; mentally. I&rsquo;ve a lot more respect for long running OSS maintainers now than I did before. I have a lot of personal work to do before I become anything like a decent maintainer.</li>
<li>Lots of people love Gerrit, and they also hate Gerrit :D Gerrit is very powerful, but the UX is so user hostile - I don&rsquo;t think these are unrelated. I hope that some of the power of Gerrit transfers to GitHub, but at the same time GitHub does not become anything like Gerrit! Also, people have very strong opinions about how their git histories should look like - perhaps they spend a lot more time looking through it than I do?</li>
<li>We are slowly developing better ways of dealing with Trolls in projects, but still have a long, long way to go. &ldquo;Look for the helpers&rdquo; here.</li>
</ol>

<p>It was also great to go to a short, well organized (un)conference targeted at diverse group of people who are still like me in some sense! Would go again, A+++!</p>

</article> 






<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="http://words.yuvi.in/post/designing-data-intensive-applications/">designing data intensive applications</a></h2>
    <p class="blog-post-meta"><time datetime="2017-07-02T22:47:06-07:00">Sun Jul 2, 2017</time> by  in 

<i class="fa fa-tag" aria-hidden="true"></i>&nbsp;<a href="/tags/learning" rel="tag">learning</a>

</p>
  </header>
  

<p>I&rsquo;ve been reading <a href="http://dataintensive.net/">Designing Data Intensive Applications</a> book &amp; am using this post to keep notes!</p>

<p>I&rsquo;ve picked up ideas on scaling systems through the years, but never actually sat down to actually study them semi-formally. This seems like a great start to it!</p>

<p>It&rsquo;s a pretty big book, and it&rsquo;s gonna take me a while to go through it :) Will update these notes as I go! Trying to do a chapter a week!</p>

<h2 id="chapter-1-defining-all-the-things">Chapter 1: Defining all the things</h2>

<blockquote>
<p>The Internet was done so well that most people think of it as a natural resource like the Pacific Ocean, rather than something that was man-made. When was the last time a technology with a scale like that was so error-free?
Alan Kay, in <a href="www.drdobbs.com/architecture-and-design/interview-with-alan-kay/240003442">interview with Dr Dobb’s Journal (2012)</a></p>
</blockquote>

<p>I keep forgetting what an amazing marvel the internet is and how intensely (and mostly positively, thankfully) it has affected my life. This is a good reminder! However, perhaps to people who haven&rsquo;t had the privileges I&rsquo;ve had the Internet doesn&rsquo;t feel like a natural resource? Unsure! Should ask them!</p>

<p>Lots of modern applications are data intensive, rather than CPU intensive.
&gt;  Raw CPU power is rarely a limiting factor for these applications—bigger problems are usually the amount of data, the complexity of data, and the speed at which it is changing.</p>

<p>This has borne out in the infrastructure I&rsquo;ve been setting up to help teach people data science - RAM is often the bottleneck, not CPU (barring machine-learning type stuff, but they want GPUs anyway).</p>

<p>Common building blocks for data intensive applications are:</p>

<ol>
<li>Store data so that they, or another application, can find it again later (databases)</li>
<li>Remember the result of an expensive operation, to speed up reads (caches)</li>
<li>Allow users to search data by keyword or filter it in various ways (search indexes)</li>
<li>Send a message to another process, to be handled asynchronously (stream processing)</li>
<li>Periodically crunch a large amount of accumulated data (batch processing)</li>
</ol>

<p>These <em>do</em> seem to cover a large variety of bases! I feel fairly comfortable in operating, using and building on top of some of these (databases, caches) but not so much in most (never used a search index, batch processing, nor streams outside of redis). Partially I haven&rsquo;t felt an intense need for these, but perhaps if I understand them more I&rsquo;ll use them more? I&rsquo;ve mostly strived to make everything stateless - but perhaps that&rsquo;s causing me to shy away from problems that can only be solved with state? /me ponders.</p>

<p>Boundaries around &lsquo;data systems&rsquo; are blurring - Redis is a cache but can be a message queue, Apache Kafka is a message queue that can have durability guarantees, etc. Lots of applications also need more than can be done with just one tool (aka a &lsquo;pure LAMP&rsquo; stack is no longer good enough). Applications often have the job of making sure different data sources are in sync. Everyone is a &lsquo;data designer&rsquo;, and everyone is kinda fucked.</p>

<p>Talk about 3 things that are most important to any software system.</p>

<h3 id="reliability">Reliability</h3>

<p>Means &lsquo;continue to work correctly, even when things go wrong&rsquo;. Things that go wrong are &lsquo;faults&rsquo;, and systems need to be &lsquo;fault-tolerent&rsquo; or &lsquo;resilient&rsquo;. Can&rsquo;t be tolerant of all faults, so gotta define what faults we&rsquo;re tolerant of.</p>

<p>Fault isn&rsquo;t failure - fault is when a component of the system &lsquo;deviates from its spec&rsquo;, <em>failure</em> is when the system as a whole stops providing user server they want. Can&rsquo;t reduce chances of fault to zero, but can work on reducing failures to zero.</p>

<p><strong>Engineering is building reliable systems from unreliable parts.</strong></p>

<p>Chaos monkeys are good, increase faults to find ways to reduce failure.</p>

<p>Hardware reliability - physical components fail. Nothing you can do about it. Fix it in software.</p>

<p>Hardware faults <em>usually</em> not corelated - one macine failing doesn&rsquo;t cause another machine to fail. To truly fuck shit up you need software - can easily cause massive large scale failure! For example, a leap second bug! Or a runaway process that slowly kills every other process on the machine. One of the microservies that 50 of your microservices depend on is slow! Cascading failures! These bugs all lie dormant, until they suddenly aren&rsquo;t and wreak havok. The software makes some assumption about its environment, which is true until it isn&rsquo;t. No quick solution to systematic software faults.</p>

<p>Human error is worst error. The book offers some suggestions on how to prevent these.</p>

<ol>
<li>Minimize opportunities for errors - make it easy to do the right thing. But if it&rsquo;s too restrictive, people will work around it - tricky balance.</li>
<li>Provide full featured sandboxes so people can fuck around without fucking shit up.</li>
<li>AUTOMATICALLY TEST EVERYTHING so when a human does fuck up, they know!</li>
<li>Set up undo functionality, so when human does fuck up, they can roll back!</li>
</ol>

<p>Learn about telemetry from other disciplines that have been doing this shit for far longer than us. <a href="https://xkcd.com/1831/">Relevant XKCD</a></p>

<p>Reliability isn&rsquo;t just for nukes &amp; aircraft &amp; election systems (haha). Imagine someone loses a video of their kid&rsquo;s first ever step because you didn&rsquo;t care. Fucking up is human and we all do it - what is important is that we care.</p>

<p>Sometimes you gotta sacrifice reliability, but make sure that is an explicit &amp; conscious decision. Actually throw away your prototypes! Put FIXMEs in your code. Take a shower. Make sure hacks look, feel and sound hacky!</p>

<h3 id="scalability">Scalability</h3>

<p>System&rsquo;s ability to adapt to increased &lsquo;load&rsquo; along some axes.</p>

<p>Load is described with various <em>load parameters</em>, which depend on the system (req/s? active users? etc).</p>

<p>Carefully define what this means for your application, and explain your reasoning. You might have to scale in some aspects but not in other.</p>

<p>Once you have the load parameters for your app defined, figure out what happens when you increase load parameters but keep system resources unchanged. After that, try to figure out how much resources need to be increased.</p>

<p>Throughput - number of things that can be done per second. Latency is time it takes to serve a request. These are common things we care about when we move load parameters up and down.</p>

<p>You shouldn&rsquo;t think of these as single numbers, since they vary a fair bit. Think of these as <em>probability distributions</em>. Learn some statistics! Use percentiles, rather than &lsquo;average&rsquo; or &lsquo;mean&rsquo;.</p>

<p>High percentile latencies are especially important when you are a service that&rsquo;s called by many other services - it can cascade down.</p>

<p>No <em>magic scaling sauce</em> - architecture that can scale is different for each application. But there are general purpose building blocks, so worry a little less!</p>

<h3 id="maintainability">Maintainability</h3>

<blockquote>
<p>Always code as if the person who ends up maintaining your code is a violent psychopath who knows where you live.</p>
</blockquote>

<p>Split into three major aspects.</p>

<p><strong>Operability</strong></p>

<p>Make it easy for people to operate your service! Help them monitor the health of the system, observe &amp; debug problems, do capacity planning, keep the production environment stable, prevent single human points of failure (oh, only Chad knows about this system) and many other things!</p>

<p><strong>Simplicity</strong></p>

<p>Don&rsquo;t make your software a big ball of mud. Take into account that new engineers will have to start working on your software, and they need to understand it quickly.</p>

<p>Use standard tools &amp; approaches they have a higher likelihood of knowing - look around for standard tools before inventing your own!</p>

<p>Watch out for accidental complexity, and keep it to a minimum as much as possible. Abstractions are good, but abstractions are also leaky.</p>

<p><strong>Evolvability</strong></p>

<p>If your software is simple &amp; has good abstractions, you can change it over time without wanting to pull all your hair out.</p>

</article> 





<nav class="blog-pagination">
  
  
  
  <a class="btn btn-outline-primary disabled" href="#" role="button" aria-disabled="true">Previous page</a>
  <a class="btn btn-outline-primary" href="/page/2/" rel="next" role="button">Next page</a>
  
</nav>




        </div> <!-- /.blog-main -->

        <aside class="col-sm-3 ml-auto blog-sidebar">
  
  <section class="sidebar-module sidebar-module-inset">
    <h4>about</h4>
    <p>I build infrastructure that helps reduce accidental complexities when using code to solve problems.</p>
  </section>
  
  <section class="sidebar-module sidebar-module-inset">
    <h4>projects</h4>
    <p><p>Primarily working on <a href="https://z2jh.jupyter.org">Zero to JupyterHub</a> and <a href="https://mybinder.org">MyBinder</a></p>

<p>See more on my <a href="https://github.com/yuvipanda">GitHub Profile</a></p>
</p>
  </section>
  
  <section class="sidebar-module sidebar-module-inset">
    <h4>work</h4>
    <p><p>I design, build &amp; operate large scale teaching infrastructure for the <a href="https://data.berkeley.edu/">Data Science Division at UC Berkeley</a>.</p>

<p>I also help run <a href="https://mybinder.org">MyBinder</a> thanks to a generous grant from the Gordon &amp; Betty Moore Foundation.</p>
</p>
  </section>
  
  <section class="sidebar-module sidebar-module-inset">
    <h4>contact</h4>
    <p><a href="mailto:yuvipanda@gmail.com">Email</a> is the best way to contact me privately.
<a href="https://twitter.com/yuvipanda">Twitter</a> is the best way to contact me publicly.</p>
  </section>
  

  
        <section class="sidebar-module">
    <h4>Recent Posts</h4>
    <ol class="list-unstyled">


<li><a href="/post/devlog-2018-12-23/">DevLog 2018 December 23</a></li>

<li><a href="/post/oss-in-the-cloud/">Freedoms for Open Source Software users in the Cloud</a></li>

<li><a href="/post/aug-2018-plan/">Aug 2018 Work Plan</a></li>

<li><a href="/post/conda-constructor-thoughts/">Conda Constructor Thoughts</a></li>

<li><a href="/post/the-littlest-jupyterhub/">The Littlest Jupyterhub</a></li>

    </ol>
  </section>

  

  
</aside>


      </div> <!-- /.row -->
    </div> <!-- /.container -->

    <footer class="blog-footer">
      <p>
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
      <p>
      <a href="#">Back to top</a>
      </p>
    </footer>

  </body>

</html>
